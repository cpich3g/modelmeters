# 1 February 2025

### Azure OpenAI

- o3 mini 0131:
  - Token-based pricing for Input, Output, Batch, Cached, and Data Zone/Global/regional meters.
  - Prices vary by meter; token rates start from $0.00055/1k tokens.
- o1:
  - Batch input/output meters for Global and Data Zone usage.
  - Pricing differentiated between input and output; starts from $0.0075/1k tokens.
- o1 1217:
  - Versioned o1 (1217) Batch meters for input/output across Global and Data Zone.
  - Pricing aligned with o1 series, from $0.0075/1k tokens.
- o1 mini:
  - Lower-cost o1 variant with Batch input/output for Global and Data Zone.
  - Token rates start from $0.00055/1k tokens.
- gpt-4-8K:
  - Regional meters for Input and Output tokens.
  - Pricing starts from $0.0363/1k tokens.
- gpt-4-turbo128K:
  - Global meters for Input and Output tokens.
  - Pricing starts from $0.01/1k tokens.

Relevant documentation:
- Azure OpenAI overview and model list (includes o-series and GPT-4 family): https://learn.microsoft.com/en-us/azure/ai-foundry/openai/overview
- Azure OpenAI model catalog and o-series models (o3-mini, o1, o1-mini): https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/models#o-series-models
- Foundry models sold directly by Azure (Azure OpenAI, including GPT-4 Turbo): https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/concepts/models-sold-directly-by-azure
- General Azure OpenAI model availability (includes GPT-4 variants): https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/models

### Phi

- Phi-4:
  - Fine-tuning and inference meters for Input, Output, and combined FT tokens.
  - Includes a Deployment Hosting Unit (per-hour hosting).
  - Token prices start from $0.000125/1k tokens; hosting is $0.8/hour.
- Phi-4-Mini:
  - Inference and FT meters for Input and Output tokens, plus FT Tokens and Deployment Hosting Units.
  - Very low-cost SLM-style pricing, starting from $0.000075/1k tokens; hosting is $0.8/hour.
- Phi-4-Mini MM (multimodal):
  - Multimodal FT and non-FT Input/Output token meters (MM-Input, MM-Output, MM-FT), plus hosting.
  - Supports both standard and FT usage, with pricing from $0.00008/1k tokens; hosting is $0.8/hour.

Relevant documentation:
- Foundry models from Microsoft (Phi model family, including Phi-4 and Phi-4-mini-instruct): https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/concepts/models-from-partners?view=foundry-classic#microsoft
- Featured models in Foundry catalog (Phi-4, Phi-4-mini, Phi-4-multimodal): https://learn.microsoft.com/en-us/azure/machine-learning/concept-models-featured?view=azureml-api-2#microsoft
- Phi-4 model card in Azure AI Foundry: https://ai.azure.com/explore/models/Phi-4/version/2/registry/azureml/?cid=learnDocs
- Phi-4-mini-instruct model card in Azure AI Foundry: https://ai.azure.com/explore/models/Phi-4-mini-instruct/version/1/registry/azureml/?cid=learnDocs

### Deepseek model family

- DeepSeek R1:
  - Input and Output token meters across Global, regional, and Data Zone variants.
  - Pricing differentiates by Input vs Output and geography tier; token rates start from $0.00135/1k tokens.

Relevant documentation:
- DeepSeek models sold directly by Azure (DeepSeek-R1 family): https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/concepts/models-sold-directly-by-azure?view=foundry-classic#deepseek-models-sold-directly-by-azure
- Tutorial: Get started with DeepSeek-R1 reasoning model in Foundry Models: https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/tutorials/get-started-deepseek-r1
- Developing reasoning apps with DeepSeek models using OpenAI SDK: https://learn.microsoft.com/en-us/azure/developer/ai/how-to/use-reasoning-model-inference

_This summary was AI-generated in 23 seconds on 23 November 2025 using gpt-5.1 with low reasoning effort.<br>It may contain mistakes, or outdated pricing data. Always use the Azure Retail Prices API for live pricing. The existence of a price meter does not always imply model/service availability. Prices vary depending on different factors, including region.<br>Input tokens: 22,340 | Output tokens: 2,362 | Total tokens: 24,702._